{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUnionBBox(aBB, bBB, ih, iw):\n",
    "    margin = 10\n",
    "    return [max(0, min(aBB[0], bBB[0]) - margin),\n",
    "            max(0, min(aBB[1], bBB[1]) - margin),\n",
    "            min(iw, max(aBB[2], bBB[2]) + margin),\n",
    "            min(ih, max(aBB[3], bBB[3]) + margin)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAppr(im, bb):\n",
    "    subim = im[bb[1] : bb[3], bb[0] : bb[2], :]\n",
    "    subim = cv2.resize(subim, None, None, 224.0 / subim.shape[1], 224.0 / subim.shape[0], interpolation=cv2.INTER_LINEAR)\n",
    "    #pixel_means = np.array([[[103.939, 116.779, 123.68]]])\n",
    "    #subim -= pixel_means\n",
    "    subim = subim / 255.0\n",
    "    return subim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDualMask(ih, iw, bb):\n",
    "    rh = 32.0 / ih\n",
    "    rw = 32.0 / iw\n",
    "    x1 = max(0, int(math.floor(bb[0] * rw)))\n",
    "    x2 = min(32, int(math.ceil(bb[2] * rw)))\n",
    "    y1 = max(0, int(math.floor(bb[1] * rh)))\n",
    "    y2 = min(32, int(math.ceil(bb[3] * rh)))\n",
    "    mask = np.zeros((32, 32))\n",
    "    mask[y1 : y2, x1 : x2] = 1\n",
    "    assert(mask.sum() == (y2 - y1) * (x2 - x1))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_batch(model, ims, poses, qas, qbs):\n",
    "    test_set = []\n",
    "    for i in range(ims.shape[0]):\n",
    "        test_set.append({'qa': qas[i], 'qb': qbs[i], 'im': ims[i], 'posdata': poses[i]})\n",
    "\n",
    "    test_elements = tuple(test_set)\n",
    "    test_dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: test_elements, {'qa': tf.int32, 'qb': tf.int32, 'im': tf.float32, 'posdata': tf.float32}\n",
    "    )\n",
    "    test_dataset = test_dataset.cache().batch(ims.shape[0]).prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    for sample in test_dataset:\n",
    "        itr_pred = model(sample['qa'], sample['qb'], sample['im'], sample['posdata'])\n",
    "    \n",
    "    return itr_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, out_path):\n",
    "    num_img = len(image_paths)\n",
    "    num_class = 101\n",
    "    thresh = 0.05\n",
    "    batch_size = 20\n",
    "    pred = []\n",
    "    pred_bboxes = []\n",
    "\n",
    "    for i in range(num_img):\n",
    "        im = cv2.imread(image_paths[i]).astype(np.float32, copy=False)\n",
    "        ih = im.shape[0]\n",
    "        iw = im.shape[1]\n",
    "        gts = np.array(all_gts[i])\n",
    "        gt_bboxes = np.array(all_gt_bboxes[i])\n",
    "        num_gts = gts.shape[0]\n",
    "        pred.append([])\n",
    "        pred_bboxes.append([])\n",
    "        ims = []\n",
    "        poses = []\n",
    "        qas = []\n",
    "        qbs = []\n",
    "        for j in range(num_gts):\n",
    "            sub = gt_bboxes[j, 0, :]\n",
    "            obj = gt_bboxes[j, 1, :]\n",
    "            rBB = getUnionBBox(sub, obj, ih, iw)\n",
    "            rAppr = getAppr(im, rBB)\n",
    "            rMask = np.array([getDualMask(ih, iw, sub), getDualMask(ih, iw, obj)])\n",
    "            ims.append(rAppr)\n",
    "            poses.append(rMask)\n",
    "            qa = np.zeros(num_class - 1)\n",
    "            qa[gts[j, 0] - 1] = 1\n",
    "            qb = np.zeros(num_class - 1)\n",
    "            qb[gts[j, 2] - 1] = 1\n",
    "            qas.append(qa)\n",
    "            qbs.append(qb)\n",
    "        if len(ims) == 0:\n",
    "            continue\n",
    "        ims = np.array(ims)\n",
    "        poses = np.array(poses)\n",
    "        qas = np.array(qas)\n",
    "        qbs = np.array(qbs)\n",
    "        poses = poses.transpose((0, 2, 3, 1))\n",
    "        _cursor = 0\n",
    "        itr_pred = None\n",
    "        num_ins = ims.shape[0]\n",
    "        while _cursor < num_ins:\n",
    "            _end_batch = min(_cursor + batch_size, num_ins)\n",
    "            itr_pred_batch = forward_batch(model, ims[_cursor : _end_batch], poses[_cursor : _end_batch], qas[_cursor : _end_batch], qbs[_cursor : _end_batch])\n",
    "            if itr_pred is None:\n",
    "                itr_pred = itr_pred_batch\n",
    "            else:\n",
    "                itr_pred = np.vstack((itr_pred, itr_pred_batch))\n",
    "            _cursor = _end_batch\n",
    "\n",
    "        for j in range(num_gts):\n",
    "            sub = gt_bboxes[j, 0, :]\n",
    "            obj = gt_bboxes[j, 1, :]\n",
    "            for k in range(itr_pred.shape[1]):\n",
    "                if itr_pred[j, k] < thresh: \n",
    "                    continue\n",
    "                pred[i].append([itr_pred[j, k], 1, 1, gts[j, 0], k, gts[j, 2]])\n",
    "                pred_bboxes[i].append([sub, obj])\n",
    "        pred[i] = np.array(pred[i])\n",
    "        pred_bboxes[i] = np.array(pred_bboxes[i])\n",
    "\n",
    "    print(\"writing file..\")\n",
    "    np.savez(out_path, pred=pred, pred_bboxes=pred_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeArea(bb):\n",
    "    return max(0, bb[2] - bb[0] + 1) * max(0, bb[3] - bb[1] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIoU(bb1, bb2):\n",
    "    ibb = [max(bb1[0], bb2[0]), \\\n",
    "        max(bb1[1], bb2[1]), \\\n",
    "        min(bb1[2], bb2[2]), \\\n",
    "        min(bb1[3], bb2[3])]\n",
    "    iArea = computeArea(ibb)\n",
    "    uArea = computeArea(bb1) + computeArea(bb2) - iArea\n",
    "    return (iArea + 0.0) / uArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeOverlap(detBBs, gtBBs):\n",
    "    aIoU = computeIoU(detBBs[0, :], gtBBs[0, :])\n",
    "    bIoU = computeIoU(detBBs[1, :], gtBBs[1, :])\n",
    "    return min(aIoU, bIoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_recall(det_file_path, num_dets=50, ov_thresh=0.5):\n",
    "    det_file = np.load(det_file_path, allow_pickle=True)\n",
    "    dets = det_file['pred']\n",
    "    det_bboxes = det_file['pred_bboxes']\n",
    "    num_img = len(dets)\n",
    "    tp = []\n",
    "    fp = []\n",
    "    score = []\n",
    "    total_num_gts = 0\n",
    "    for i in range(num_img):\n",
    "        gts = np.array(all_gts[i])\n",
    "        gt_bboxes = np.array(all_gt_bboxes[i])\n",
    "        num_gts = gts.shape[0]\n",
    "        total_num_gts += num_gts\n",
    "        gt_detected = np.zeros(num_gts)\n",
    "        if isinstance(dets[i], np.ndarray) and dets[i].shape[0] > 0:\n",
    "            det_score = np.log(dets[i][:, 0]) + np.log(dets[i][:, 1]) + np.log(dets[i][:, 2])\n",
    "            inds = np.argsort(det_score)[::-1]\n",
    "            if num_dets > 0 and num_dets < len(inds):\n",
    "                inds = inds[:num_dets]\n",
    "            top_dets = dets[i][inds, 3:]\n",
    "            top_scores = det_score[inds]\n",
    "            top_det_bboxes = det_bboxes[i][inds, :]\n",
    "            num_dets = len(inds)\n",
    "            for j in range(num_dets):\n",
    "                ov_max = 0\n",
    "                arg_max = -1\n",
    "                for k in range(num_gts):\n",
    "                    if gt_detected[k] == 0 and top_dets[j, 0] == gts[k, 0] and top_dets[j, 1] == gts[k, 1] and top_dets[j, 2] == gts[k, 2]:\n",
    "                        ov = computeOverlap(top_det_bboxes[j, :, :], gt_bboxes[k, :, :])\n",
    "                        if ov >= ov_thresh and ov > ov_max:\n",
    "                            ov_max = ov\n",
    "                            arg_max = k\n",
    "                if arg_max != -1:\n",
    "                    gt_detected[arg_max] = 1\n",
    "                    tp.append(1)\n",
    "                    fp.append(0)\n",
    "                else:\n",
    "                    tp.append(0)\n",
    "                    fp.append(1)\n",
    "                score.append(top_scores[j])\n",
    "    score = np.array(score)\n",
    "    tp = np.array(tp)\n",
    "    fp = np.array(fp)\n",
    "    inds = np.argsort(score)\n",
    "    inds = inds[::-1]\n",
    "    tp = tp[inds]\n",
    "    fp = fp[inds]\n",
    "    tp = np.cumsum(tp)\n",
    "    fp = np.cumsum(fp)\n",
    "    recall = (tp + 0.0) / total_num_gts\n",
    "    top_recall = recall[-1]\n",
    "    print('Recall:', top_recall)\n",
    "    return top_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = './reltrain.json'\n",
    "nclass = 100\n",
    "\n",
    "samples = json.load(open(dataset))\n",
    "num_instance = len(samples)\n",
    "name_to_top_map = {\"qa\": 0, \"qb\": 1, \"im\": 2, \"posdata\": 3, \"labels\": 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "qas = []\n",
    "qbs = []\n",
    "ims = []\n",
    "poses = []\n",
    "labels = []\n",
    "\n",
    "for i in range(num_instance):\n",
    "    sample = samples[i]\n",
    "    im = cv2.imread(sample[\"imPath\"]).astype(np.float32, copy=False)\n",
    "    ih = im.shape[0]\n",
    "    iw = im.shape[1]\n",
    "    qa = np.zeros(nclass)\n",
    "    qa[sample[\"aLabel\"] - 1] = 1\n",
    "    qas.append(qa)\n",
    "    qb = np.zeros(nclass)\n",
    "    qb[sample[\"bLabel\"] - 1] = 1\n",
    "    qbs.append(qb)\n",
    "    ims.append(getAppr(im, sample[\"rBBox\"]))\n",
    "    poses.append([getDualMask(ih, iw, sample[\"aBBox\"]), \n",
    "                  getDualMask(ih, iw, sample[\"bBBox\"])])\n",
    "    labels.append(sample[\"rLabel\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = np.array(poses).transpose((0, 2, 3, 1))\n",
    "\n",
    "qa = np.array(qas)\n",
    "qb = np.array(qbs)\n",
    "im = np.array(ims)\n",
    "posdata = np.array(poses)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = []\n",
    "\n",
    "for i in range(num_instance):\n",
    "    train_set.append({'qa': qa[i], 'qb': qb[i], 'im': im[i], 'posdata': posdata[i], 'labels': labels[i]})\n",
    "    \n",
    "train_elements = tuple(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: train_elements, {'qa': tf.int32, 'qb': tf.int32, 'im': tf.float32, 'posdata': tf.float32, 'labels': tf.int32}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : {'qa': <tf.Tensor: id=42, shape=(100,), dtype=int32, numpy=\n",
      "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])>, 'qb': <tf.Tensor: id=43, shape=(100,), dtype=int32, numpy=\n",
      "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])>, 'im': <tf.Tensor: id=39, shape=(224, 224, 3), dtype=float32, numpy=\n",
      "array([[[1.        , 0.94425774, 0.9089636 ],\n",
      "        [0.99596465, 0.9567489 , 0.9175332 ],\n",
      "        [1.        , 0.96431196, 0.9294036 ],\n",
      "        ...,\n",
      "        [0.9795681 , 0.92156047, 0.88599443],\n",
      "        [0.8790441 , 0.7984731 , 0.8099415 ],\n",
      "        [0.43565053, 0.33568677, 0.32837635]],\n",
      "\n",
      "       [[1.        , 0.94509804, 0.9098039 ],\n",
      "        [1.        , 0.95306313, 0.91384745],\n",
      "        [1.        , 0.95686275, 0.9254902 ],\n",
      "        ...,\n",
      "        [0.9762148 , 0.917367  , 0.8821216 ],\n",
      "        [0.87817067, 0.78274935, 0.8033451 ],\n",
      "        [0.39149845, 0.280671  , 0.31518546]],\n",
      "\n",
      "       [[1.        , 0.94497615, 0.90968204],\n",
      "        [0.9996342 , 0.9549701 , 0.91575444],\n",
      "        [1.        , 0.95686275, 0.9254902 ],\n",
      "        ...,\n",
      "        [0.97901475, 0.9126776 , 0.87900037],\n",
      "        [0.89340484, 0.78938204, 0.83883804],\n",
      "        [0.41045418, 0.278472  , 0.33633327]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.39474165, 0.38342398, 0.39037302],\n",
      "        [0.33667466, 0.32257468, 0.33400983],\n",
      "        [0.34738645, 0.3277786 , 0.33170018],\n",
      "        ...,\n",
      "        [0.47743407, 0.4852772 , 0.48919877],\n",
      "        [0.46045917, 0.4683023 , 0.47222388],\n",
      "        [0.46328154, 0.4714223 , 0.4778649 ]],\n",
      "\n",
      "       [[0.36938086, 0.36153772, 0.3612695 ],\n",
      "        [0.39797795, 0.38953894, 0.39209622],\n",
      "        [0.37528074, 0.35669705, 0.3602772 ],\n",
      "        ...,\n",
      "        [0.44306663, 0.4409364 , 0.45483133],\n",
      "        [0.44245636, 0.45064086, 0.45570853],\n",
      "        [0.42114595, 0.4315451 , 0.44936162]],\n",
      "\n",
      "       [[0.36628902, 0.34668118, 0.35368398],\n",
      "        [0.36874124, 0.34151784, 0.35309562],\n",
      "        [0.38079357, 0.36118573, 0.3651073 ],\n",
      "        ...,\n",
      "        [0.42387894, 0.43172207, 0.43564364],\n",
      "        [0.4593356 , 0.46717873, 0.4711003 ],\n",
      "        [0.41614208, 0.42024246, 0.43592873]]], dtype=float32)>, 'posdata': <tf.Tensor: id=41, shape=(32, 32, 2), dtype=float32, numpy=\n",
      "array([[[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]],\n",
      "\n",
      "       [[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]],\n",
      "\n",
      "       [[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]],\n",
      "\n",
      "       [[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]],\n",
      "\n",
      "       [[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        ...,\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.]]], dtype=float32)>, 'labels': <tf.Tensor: id=40, shape=(), dtype=int32, numpy=26>}\n",
      "2 : {'qa': <tf.Tensor: id=47, shape=(100,), dtype=int32, numpy=\n",
      "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])>, 'qb': <tf.Tensor: id=48, shape=(100,), dtype=int32, numpy=\n",
      "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])>, 'im': <tf.Tensor: id=44, shape=(224, 224, 3), dtype=float32, numpy=\n",
      "array([[[0.9851191 , 0.9262956 , 0.89100146],\n",
      "        [0.98677224, 0.92736095, 0.89324236],\n",
      "        [0.9882353 , 0.92941177, 0.89411765],\n",
      "        ...,\n",
      "        [0.9346989 , 0.8837185 , 0.85234594],\n",
      "        [0.9260779 , 0.8750975 , 0.84372497],\n",
      "        [0.9250025 , 0.8740221 , 0.8426496 ]],\n",
      "\n",
      "       [[0.98308074, 0.9184449 , 0.88315076],\n",
      "        [0.98721987, 0.92445225, 0.88355345],\n",
      "        [0.9814076 , 0.922584  , 0.8872899 ],\n",
      "        ...,\n",
      "        [0.93305326, 0.88207287, 0.85070026],\n",
      "        [0.9254902 , 0.8745098 , 0.84313726],\n",
      "        [0.92156863, 0.87058824, 0.8392157 ]],\n",
      "\n",
      "       [[0.9843137 , 0.9207283 , 0.8761905 ],\n",
      "        [0.9882353 , 0.9254902 , 0.8784314 ],\n",
      "        [0.98752   , 0.92156863, 0.8862745 ],\n",
      "        ...,\n",
      "        [0.92941177, 0.8784314 , 0.84705883],\n",
      "        [0.9254902 , 0.8745098 , 0.84313726],\n",
      "        [0.92156863, 0.87058824, 0.8392157 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.3554597 , 0.34761655, 0.34483796],\n",
      "        [0.3947829 , 0.39387503, 0.39415014],\n",
      "        [0.40608993, 0.39709136, 0.3974765 ],\n",
      "        ...,\n",
      "        [0.46337786, 0.47014806, 0.47514257],\n",
      "        [0.45181322, 0.4631928 , 0.4789866 ],\n",
      "        [0.45127052, 0.44888955, 0.4578056 ]],\n",
      "\n",
      "       [[0.3630252 , 0.3502676 , 0.3527036 ],\n",
      "        [0.3754552 , 0.35584736, 0.36116946],\n",
      "        [0.37067327, 0.35106543, 0.354987  ],\n",
      "        ...,\n",
      "        [0.43557423, 0.44341737, 0.44733894],\n",
      "        [0.47294167, 0.4807848 , 0.48470637],\n",
      "        [0.44162914, 0.45295867, 0.46864495]],\n",
      "\n",
      "       [[0.35557225, 0.3359644 , 0.34296718],\n",
      "        [0.33806524, 0.31061426, 0.32355443],\n",
      "        [0.37711835, 0.3575105 , 0.36143208],\n",
      "        ...,\n",
      "        [0.43140507, 0.4392482 , 0.44316977],\n",
      "        [0.4467162 , 0.45455933, 0.4584809 ],\n",
      "        [0.4132453 , 0.4175195 , 0.43214783]]], dtype=float32)>, 'posdata': <tf.Tensor: id=46, shape=(32, 32, 2), dtype=float32, numpy=\n",
      "array([[[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        ...,\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]],\n",
      "\n",
      "       [[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        ...,\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]],\n",
      "\n",
      "       [[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        ...,\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]],\n",
      "\n",
      "       [[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]],\n",
      "\n",
      "       [[1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        ...,\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]]], dtype=float32)>, 'labels': <tf.Tensor: id=45, shape=(), dtype=int32, numpy=15>}\n",
      "3 : {'qa': <tf.Tensor: id=52, shape=(100,), dtype=int32, numpy=\n",
      "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])>, 'qb': <tf.Tensor: id=53, shape=(100,), dtype=int32, numpy=\n",
      "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])>, 'im': <tf.Tensor: id=49, shape=(224, 224, 3), dtype=float32, numpy=\n",
      "array([[[0.9866681 , 0.9469272 , 0.92105186],\n",
      "        [0.9887605 , 0.9490196 , 0.9231442 ],\n",
      "        [0.9887605 , 0.9490196 , 0.9231442 ],\n",
      "        ...,\n",
      "        [0.9456232 , 0.89512587, 0.8627873 ],\n",
      "        [0.9489496 , 0.8979692 , 0.86659664],\n",
      "        [0.9495448 , 0.89888805, 0.8668683 ]],\n",
      "\n",
      "       [[0.99118614, 0.9512002 , 0.9355139 ],\n",
      "        [0.99215686, 0.95217085, 0.9364846 ],\n",
      "        [0.99215686, 0.95217085, 0.9364846 ],\n",
      "        ...,\n",
      "        [0.9505952 , 0.9033479 , 0.8645092 ],\n",
      "        [0.95258516, 0.90318036, 0.8686565 ],\n",
      "        [0.9529412 , 0.9049817 , 0.86756736]],\n",
      "\n",
      "       [[0.9939848 , 0.9586907 , 0.9430044 ],\n",
      "        [0.9947829 , 0.9594888 , 0.94380254],\n",
      "        [0.9947829 , 0.9594888 , 0.94380254],\n",
      "        ...,\n",
      "        [0.9529412 , 0.90588236, 0.8666667 ],\n",
      "        [0.9529412 , 0.90588236, 0.8666667 ],\n",
      "        [0.954559  , 0.9075002 , 0.8682845 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0.45697406, 0.4491309 , 0.4491309 ],\n",
      "        [0.4632353 , 0.45539215, 0.45539215],\n",
      "        [0.46355417, 0.45571104, 0.45571104],\n",
      "        ...,\n",
      "        [0.36344728, 0.3359963 , 0.3242316 ],\n",
      "        [0.37025434, 0.34280336, 0.33103865],\n",
      "        [0.35964322, 0.33219224, 0.32042754]],\n",
      "\n",
      "       [[0.46427009, 0.45642695, 0.45642695],\n",
      "        [0.44923562, 0.44139248, 0.44139248],\n",
      "        [0.46551934, 0.4576762 , 0.45551878],\n",
      "        ...,\n",
      "        [0.37577844, 0.34832746, 0.33656275],\n",
      "        [0.35458153, 0.32713056, 0.31536585],\n",
      "        [0.3407638 , 0.3147581 , 0.30010286]],\n",
      "\n",
      "       [[0.45469064, 0.4468475 , 0.4468475 ],\n",
      "        [0.44056562, 0.43272248, 0.43272248],\n",
      "        [0.44595185, 0.4381087 , 0.43762568],\n",
      "        ...,\n",
      "        [0.35651168, 0.3290607 , 0.317296  ],\n",
      "        [0.3528749 , 0.32542393, 0.31365922],\n",
      "        [0.34638387, 0.32265282, 0.30344826]]], dtype=float32)>, 'posdata': <tf.Tensor: id=51, shape=(32, 32, 2), dtype=float32, numpy=\n",
      "array([[[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        ...,\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]],\n",
      "\n",
      "       [[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        ...,\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]],\n",
      "\n",
      "       [[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        ...,\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        ...,\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]],\n",
      "\n",
      "       [[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        ...,\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]],\n",
      "\n",
      "       [[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        ...,\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]]], dtype=float32)>, 'labels': <tf.Tensor: id=50, shape=(), dtype=int32, numpy=10>}\n"
     ]
    }
   ],
   "source": [
    "for i, sample in enumerate(train_dataset.take(3)):\n",
    "    print(i+1, ':', sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = num_instance\n",
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = './reltest.json'\n",
    "nclass = 100\n",
    "\n",
    "test_samples = json.load(open(test_dataset))\n",
    "test_num_instance = len(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = []\n",
    "gt_label = []\n",
    "gt_box = []\n",
    "j = 0\n",
    "\n",
    "for i in range(test_num_instance):\n",
    "    if(i == 0):\n",
    "        gt_label.append([])\n",
    "        gt_box.append([])\n",
    "        img_path = test_samples[i]['imPath']\n",
    "        image_paths.append(img_path)\n",
    "        gt_label[j].append([test_samples[i]['aLabel'], test_samples[i]['rLabel'], test_samples[i]['bLabel']])\n",
    "        gt_box[j].append([test_samples[i]['aBBox'], test_samples[i]['bBBox']])\n",
    "    else:\n",
    "        if(img_path == test_samples[i]['imPath']):\n",
    "            gt_label[j].append([test_samples[i]['aLabel'], test_samples[i]['rLabel'], test_samples[i]['bLabel']])\n",
    "            gt_box[j].append([test_samples[i]['aBBox'], test_samples[i]['bBBox']])\n",
    "        else:\n",
    "            j += 1\n",
    "            gt_label.append([])\n",
    "            gt_box.append([])\n",
    "            img_path = test_samples[i]['imPath']\n",
    "            image_paths.append(img_path)\n",
    "            gt_label[j].append([test_samples[i]['aLabel'], test_samples[i]['rLabel'], test_samples[i]['bLabel']])\n",
    "            gt_box[j].append([test_samples[i]['aBBox'], test_samples[i]['bBBox']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gts = np.array(gt_label)\n",
    "all_gt_bboxes = np.array(gt_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AppearanceSubnet(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_shape):\n",
    "        super(AppearanceSubnet, self).__init__()\n",
    "        \n",
    "        self.conv1 = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(64, 3, padding='same', input_shape=input_shape, name='conv1_1'),\n",
    "            tf.keras.layers.ReLU(name='relu1_1'),\n",
    "            tf.keras.layers.Conv2D(64, 3, padding='same', name='conv1_2'),\n",
    "            tf.keras.layers.ReLU(name='relu1_2'),\n",
    "            tf.keras.layers.MaxPool2D(2, 2, name='pool1')\n",
    "        ])\n",
    "        \n",
    "        self.conv2 = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(128, 3, padding='same', name='conv2_1'),\n",
    "            tf.keras.layers.ReLU(name='relu2_1'),\n",
    "            tf.keras.layers.Conv2D(128, 3, padding='same', name='conv2_2'),\n",
    "            tf.keras.layers.ReLU(name='relu2_2'),\n",
    "            tf.keras.layers.MaxPool2D(2, 2, name='pool2')\n",
    "        ])\n",
    "        \n",
    "        self.conv3 = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(256, 3, padding='same', name='conv3_1'),\n",
    "            tf.keras.layers.ReLU(name='relu3_1'),\n",
    "            tf.keras.layers.Conv2D(256, 3, padding='same', name='conv3_2'),\n",
    "            tf.keras.layers.ReLU(name='relu3_2'),\n",
    "            tf.keras.layers.Conv2D(256, 3, padding='same', name='conv3_3'),\n",
    "            tf.keras.layers.ReLU(name='relu3_3'),\n",
    "            tf.keras.layers.MaxPool2D(2, 2, name='pool3')\n",
    "        ])\n",
    "        \n",
    "        self.conv4 = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(512, 3, padding='same', name='conv4_1'),\n",
    "            tf.keras.layers.ReLU(name='relu4_1'),\n",
    "            tf.keras.layers.Conv2D(512, 3, padding='same', name='conv4_2'),\n",
    "            tf.keras.layers.ReLU(name='relu4_2'),\n",
    "            tf.keras.layers.Conv2D(512, 3, padding='same', name='conv4_3'),\n",
    "            tf.keras.layers.ReLU(name='relu4_3'),\n",
    "            tf.keras.layers.MaxPool2D(2, 2, name='pool4')\n",
    "        ])\n",
    "        \n",
    "        self.conv5 = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(512, 3, padding='same', name='conv5_1'),\n",
    "            tf.keras.layers.ReLU(name='relu5_1'),\n",
    "            tf.keras.layers.Conv2D(512, 3, padding='same', name='conv5_2'),\n",
    "            tf.keras.layers.ReLU(name='relu5_2'),\n",
    "            tf.keras.layers.Conv2D(512, 3, padding='same', name='conv5_3'),\n",
    "            tf.keras.layers.ReLU(name='relu5_3'),\n",
    "            tf.keras.layers.MaxPool2D(2, 2, name='pool5')\n",
    "        ])\n",
    "        \n",
    "        self.fc = tf.keras.Sequential([\n",
    "            tf.keras.layers.Flatten(name='flat'),\n",
    "            tf.keras.layers.Dense(4096, name='fc6'),\n",
    "            tf.keras.layers.ReLU(name='relu6'),\n",
    "            tf.keras.layers.Dense(4096, name='fc7'),\n",
    "            tf.keras.layers.ReLU(name='relu7'),\n",
    "            tf.keras.layers.Dense(256, kernel_initializer='glorot_normal', name='fc8'),\n",
    "            tf.keras.layers.ReLU(name='relu8')\n",
    "        ]) \n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.conv5(out)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialSubnet(tf.keras.layers.Layer):\n",
    "    def __init__(self, input_shape):\n",
    "        super(SpatialSubnet, self).__init__()\n",
    "        \n",
    "        self.conv = tf.keras.Sequential([\n",
    "            tf.keras.layers.Conv2D(96, 5, 2, padding='same', input_shape=input_shape, name='conv1_p'),\n",
    "            tf.keras.layers.ReLU(name='relu1_p'),\n",
    "            tf.keras.layers.Conv2D(128, 5, 2, padding='same', name='conv2_p'),\n",
    "            tf.keras.layers.Conv2D(64, 8, name='conv3_p'),\n",
    "            tf.keras.layers.ReLU(name='relu3_p')\n",
    "        ])\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.conv(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombineSubnets(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(CombineSubnets, self).__init__()\n",
    "        \n",
    "        self.concat1_c = tf.keras.layers.Concatenate(name='concat1_c')\n",
    "        \n",
    "        self.fc = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(128, name='fc2_c'),\n",
    "            tf.keras.layers.ReLU(name='relu2_c'),\n",
    "            tf.keras.layers.Dense(70, kernel_initializer='glorot_normal', name='PhiR_0'),\n",
    "            tf.keras.layers.ReLU(name='relu_0')\n",
    "        ])\n",
    "        \n",
    "    def call(self, x1, x2):\n",
    "        x2 = x2[:, 0, 0, :]\n",
    "        out = self.concat1_c([x1, x2])\n",
    "        out = self.fc(out) # qr0\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, i, activation=True):\n",
    "        super(DRLayer, self).__init__()\n",
    "        \n",
    "        self.activation = activation\n",
    "        \n",
    "        self.PhiA = tf.keras.layers.Dense(70, kernel_initializer='glorot_normal', name='PhiA_%d'%(i)) # qar_i\n",
    "        self.PhiB = tf.keras.layers.Dense(70, kernel_initializer='glorot_normal', name='PhiB_%d'%(i)) # qbr_i\n",
    "        self.PhiR = tf.keras.layers.Dense(70, kernel_initializer='glorot_normal', name='PhiR_%d'%(i)) # q_i_r\n",
    "        self.QSum = tf.keras.layers.Add(name='QSum_%d'%(i)) # qr_i_un\n",
    "        if(activation == True):\n",
    "            self.relu = tf.keras.layers.ReLU(name='relu_%d'%(i)) # qr_i\n",
    "        \n",
    "    def call(self, qa, qb, qr):\n",
    "        qar = self.PhiA(qa)\n",
    "        qbr = self.PhiB(qb)\n",
    "        qr = self.PhiR(qr)\n",
    "        qrun = self.QSum([qar, qbr, qr])\n",
    "        if self.activation:\n",
    "            qr = self.relu(qrun)\n",
    "        else:\n",
    "            qr = qrun\n",
    "        return qr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class DRModule(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers):\n",
    "        super(DRModule, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.dr_layers = [DRLayer(i+1, activation=True) if((i+1) != num_layers) \n",
    "                          else DRLayer(i+1, activation=False) for i in range(num_layers)]\n",
    "        \n",
    "    def call(self, qa, qb, qr):\n",
    "        for i in range(self.num_layers):\n",
    "            qr = self.dr_layers[i](qa, qb, qr)\n",
    "        return qr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRNet(tf.keras.Model):\n",
    "    def __init__(self, num_layers=8, im_shape=(224, 224, 3), posdata_shape=(32, 32, 2)):\n",
    "        super(DRNet, self).__init__()\n",
    "        \n",
    "        self.appr = AppearanceSubnet(input_shape=im_shape)\n",
    "        self.spatial = SpatialSubnet(input_shape=posdata_shape)\n",
    "        self.combine = CombineSubnets()\n",
    "        self.dr = DRModule(num_layers=num_layers)\n",
    "        self.softmax = tf.keras.layers.Softmax()\n",
    "        \n",
    "    def call(self, qa, qb, im, posdata):\n",
    "        fc8 = self.appr(im)\n",
    "        conv3_p = self.spatial(posdata)\n",
    "        qr0 = self.combine(fc8, conv3_p)\n",
    "        qr = self.dr(qa, qb, qr0)\n",
    "        out = self.softmax(qr)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRNet(tf.keras.Model):\n",
    "    def __init__(self, num_layers=8, im_shape=(224, 224, 3), posdata_shape=(32, 32, 2)):\n",
    "        super(DRNet, self).__init__()\n",
    "        \n",
    "        self.appr = AppearanceSubnet(input_shape=im_shape)\n",
    "        #self.spatial = SpatialSubnet(input_shape=posdata_shape)\n",
    "        #self.combine = CombineSubnets()\n",
    "        #self.dr = DRModule(num_layers=num_layers)\n",
    "        self.temp_fc = tf.keras.layers.Dense(70)\n",
    "        self.softmax = tf.keras.layers.Softmax()\n",
    "        \n",
    "    def call(self, qa, qb, im, posdata):\n",
    "        fc8 = self.appr(im)\n",
    "        #conv3_p = self.spatial(posdata)\n",
    "        #qr0 = self.combine(fc8, conv3_p)\n",
    "        #qr = self.dr(qa, qb, qr0)\n",
    "        qr = self.temp_fc(fc8)\n",
    "        out = self.softmax(qr)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = DRNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.0142784  0.01428739 0.01426942 ... 0.01428815 0.01427437 0.0142937 ]\n",
      " [0.0142751  0.01428419 0.01427061 ... 0.01429363 0.01425983 0.01430507]\n",
      " [0.01427801 0.0142874  0.0142685  ... 0.0142898  0.0142664  0.01429612]\n",
      " ...\n",
      " [0.0142755  0.01429006 0.01427076 ... 0.01429318 0.01426644 0.01430127]\n",
      " [0.01427758 0.01428216 0.01427443 ... 0.01429116 0.01427181 0.01429635]\n",
      " [0.01427878 0.01428629 0.01426942 ... 0.01428832 0.01426927 0.01429617]], shape=(32, 70), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for sample in train_dataset:\n",
    "    print(model_A(sample['qa'], sample['qb'], sample['im'], sample['posdata']))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/model_A\"\n",
    "ckpt = tf.train.Checkpoint(model_A=model_A, optimizer=optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, qa, qb, im, posdata, label):\n",
    "    loss = 0\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        y = model(qa, qb, im, posdata)\n",
    "        loss += loss_object(label, y)\n",
    "        \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(label, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(model, out_path='temp.npz', num_dets=50, ov_thresh=0.5):\n",
    "    test_model(model, out_path)\n",
    "    test_recall = eval_recall(out_path, num_dets, ov_thresh)\n",
    "    return test_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                              | 1/100 [02:54<4:47:48, 174.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 6.9940 Accuracy 0.1605\n",
      "Time taken for 1 epoch: 174.43052291870117 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▌                                                                             | 2/100 [05:45<4:43:23, 173.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss 2.8981 Accuracy 0.1660\n",
      "Time taken for 1 epoch: 171.35398650169373 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▎                                                                            | 3/100 [08:37<4:39:35, 172.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss 2.8968 Accuracy 0.1667\n",
      "Time taken for 1 epoch: 171.61574745178223 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▏                                                                           | 4/100 [11:29<4:36:04, 172.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss 2.8951 Accuracy 0.1656\n",
      "Time taken for 1 epoch: 171.61362886428833 secs\n",
      "\n",
      "Epoch 5 Loss 2.8936 Accuracy 0.1659\n",
      "Time taken for 1 epoch: 171.62937903404236 secs\n",
      "\n",
      "writing file..\n",
      "Recall: 0.16483228511530398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███▉                                                                           | 5/100 [18:51<6:41:31, 253.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint for epoch 5 at ./checkpoints/model_A\\ckpt-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▋                                                                          | 6/100 [21:42<5:58:26, 228.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss 2.8932 Accuracy 0.1670\n",
      "Time taken for 1 epoch: 170.91446447372437 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▌                                                                         | 7/100 [24:34<5:28:01, 211.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss 2.8933 Accuracy 0.1672\n",
      "Time taken for 1 epoch: 171.57035994529724 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▎                                                                        | 8/100 [27:25<5:06:07, 199.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss 2.8933 Accuracy 0.1676\n",
      "Time taken for 1 epoch: 171.68561172485352 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████                                                                        | 9/100 [30:17<4:50:05, 191.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss 2.8928 Accuracy 0.1675\n",
      "Time taken for 1 epoch: 171.71502208709717 secs\n",
      "\n",
      "Epoch 10 Loss 2.8926 Accuracy 0.1678\n",
      "Time taken for 1 epoch: 171.711040019989 secs\n",
      "\n",
      "writing file..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████▊                                                                      | 10/100 [37:24<6:33:00, 262.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.1501572327044025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████████▌                                                                     | 11/100 [40:18<5:49:21, 235.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Loss 2.8934 Accuracy 0.1669\n",
      "Time taken for 1 epoch: 173.7468295097351 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▎                                                                    | 12/100 [43:10<5:17:19, 216.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Loss 2.8920 Accuracy 0.1685\n",
      "Time taken for 1 epoch: 171.62308049201965 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▏                                                                   | 13/100 [46:01<4:54:13, 202.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Loss 2.8929 Accuracy 0.1671\n",
      "Time taken for 1 epoch: 171.51315999031067 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|██████████▉                                                                   | 14/100 [48:53<4:37:20, 193.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Loss 2.8919 Accuracy 0.1679\n",
      "Time taken for 1 epoch: 171.51588940620422 secs\n",
      "\n",
      "Epoch 15 Loss 2.8927 Accuracy 0.1675\n",
      "Time taken for 1 epoch: 171.49336647987366 secs\n",
      "\n",
      "writing file..\n",
      "Recall: 0.1806865828092243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|███████████▋                                                                  | 15/100 [56:23<6:23:25, 270.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint for epoch 15 at ./checkpoints/model_A\\ckpt-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████▍                                                                 | 16/100 [59:15<5:37:14, 240.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Loss 2.8923 Accuracy 0.1663\n",
      "Time taken for 1 epoch: 171.43409132957458 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|████████████▉                                                               | 17/100 [1:02:06<5:04:26, 220.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Loss 2.8914 Accuracy 0.1680\n",
      "Time taken for 1 epoch: 171.51330375671387 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█████████████▋                                                              | 18/100 [1:04:58<4:40:51, 205.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Loss 2.8913 Accuracy 0.1680\n",
      "Time taken for 1 epoch: 171.50398302078247 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|██████████████▍                                                             | 19/100 [1:07:49<4:23:40, 195.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Loss 2.8908 Accuracy 0.1679\n",
      "Time taken for 1 epoch: 171.5336091518402 secs\n",
      "\n",
      "Epoch 20 Loss 2.8907 Accuracy 0.1667\n",
      "Time taken for 1 epoch: 171.51616263389587 secs\n",
      "\n",
      "writing file..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████▏                                                            | 20/100 [1:15:29<6:06:16, 274.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.1669287211740042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|███████████████▉                                                            | 21/100 [1:18:20<5:20:47, 243.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Loss 2.8908 Accuracy 0.1676\n",
      "Time taken for 1 epoch: 171.11683678627014 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|████████████████▋                                                           | 22/100 [1:21:12<4:48:37, 222.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Loss 2.8909 Accuracy 0.1685\n",
      "Time taken for 1 epoch: 171.56145477294922 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|█████████████████▍                                                          | 23/100 [1:24:04<4:25:30, 206.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Loss 2.8905 Accuracy 0.1681\n",
      "Time taken for 1 epoch: 171.5800838470459 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██████████████████▏                                                         | 24/100 [1:26:55<4:08:38, 196.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Loss 2.8903 Accuracy 0.1678\n",
      "Time taken for 1 epoch: 171.57830357551575 secs\n",
      "\n",
      "Epoch 25 Loss 2.8907 Accuracy 0.1684\n",
      "Time taken for 1 epoch: 171.57793474197388 secs\n",
      "\n",
      "writing file..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|███████████████████                                                         | 25/100 [1:34:20<5:38:29, 270.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.16627358490566038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|███████████████████▊                                                        | 26/100 [1:37:12<4:57:30, 241.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Loss 2.8897 Accuracy 0.1684\n",
      "Time taken for 1 epoch: 172.21651577949524 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|████████████████████▌                                                       | 27/100 [1:40:04<4:28:17, 220.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Loss 2.8896 Accuracy 0.1676\n",
      "Time taken for 1 epoch: 172.12737202644348 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|█████████████████████▎                                                      | 28/100 [1:42:56<4:07:09, 205.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Loss 2.8898 Accuracy 0.1672\n",
      "Time taken for 1 epoch: 171.93139338493347 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██████████████████████                                                      | 29/100 [1:45:48<3:51:38, 195.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Loss 2.8899 Accuracy 0.1684\n",
      "Time taken for 1 epoch: 171.8504922389984 secs\n",
      "\n",
      "Epoch 30 Loss 2.8899 Accuracy 0.1669\n",
      "Time taken for 1 epoch: 171.635427236557 secs\n",
      "\n",
      "writing file..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██████████████████████▊                                                     | 30/100 [1:53:10<5:14:31, 269.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.1669287211740042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███████████████████████▌                                                    | 31/100 [1:56:01<4:35:56, 239.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Loss 2.8894 Accuracy 0.1680\n",
      "Time taken for 1 epoch: 170.79392910003662 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|████████████████████████▎                                                   | 32/100 [1:58:51<4:08:07, 218.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Loss 2.8894 Accuracy 0.1684\n",
      "Time taken for 1 epoch: 169.87082982063293 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|█████████████████████████                                                   | 33/100 [2:01:42<3:48:37, 204.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Loss 2.8886 Accuracy 0.1679\n",
      "Time taken for 1 epoch: 171.61904525756836 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|█████████████████████████▊                                                  | 34/100 [2:04:34<3:34:16, 194.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Loss 2.8894 Accuracy 0.1677\n",
      "Time taken for 1 epoch: 171.6206510066986 secs\n",
      "\n",
      "Epoch 35 Loss 2.8893 Accuracy 0.1673\n",
      "Time taken for 1 epoch: 171.62686443328857 secs\n",
      "\n",
      "writing file..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|██████████████████████████▌                                                 | 35/100 [2:12:07<4:55:01, 272.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.16483228511530398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███████████████████████████▎                                                | 36/100 [2:14:58<4:18:07, 242.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Loss 2.8892 Accuracy 0.1672\n",
      "Time taken for 1 epoch: 171.22217464447021 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|████████████████████████████                                                | 37/100 [2:17:51<3:52:05, 221.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Loss 2.8886 Accuracy 0.1679\n",
      "Time taken for 1 epoch: 172.06705856323242 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|████████████████████████████▉                                               | 38/100 [2:20:43<3:33:12, 206.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Loss 2.8891 Accuracy 0.1676\n",
      "Time taken for 1 epoch: 171.91234183311462 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|█████████████████████████████▋                                              | 39/100 [2:23:34<3:19:16, 196.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Loss 2.8886 Accuracy 0.1684\n",
      "Time taken for 1 epoch: 171.86379289627075 secs\n",
      "\n",
      "Epoch 40 Loss 2.8884 Accuracy 0.1675\n",
      "Time taken for 1 epoch: 171.8562777042389 secs\n",
      "\n",
      "writing file..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|██████████████████████████████▍                                             | 40/100 [2:31:02<4:31:21, 271.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.16627358490566038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|███████████████████████████████▏                                            | 41/100 [2:33:54<3:57:44, 241.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Loss 2.8890 Accuracy 0.1683\n",
      "Time taken for 1 epoch: 172.70634818077087 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|███████████████████████████████▉                                            | 42/100 [2:36:46<3:33:30, 220.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Loss 2.8889 Accuracy 0.1684\n",
      "Time taken for 1 epoch: 172.03401231765747 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████████████████████████████████▋                                           | 43/100 [2:39:40<3:16:25, 206.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Loss 2.8887 Accuracy 0.1679\n",
      "Time taken for 1 epoch: 173.7770836353302 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|█████████████████████████████████▍                                          | 44/100 [2:42:32<3:03:15, 196.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Loss 2.8886 Accuracy 0.1684\n",
      "Time taken for 1 epoch: 171.9303469657898 secs\n",
      "\n",
      "Epoch 45 Loss 2.8884 Accuracy 0.1684\n",
      "Time taken for 1 epoch: 173.27389788627625 secs\n",
      "\n",
      "writing file..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|██████████████████████████████████▏                                         | 45/100 [2:50:37<4:19:10, 282.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.16627358490566038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|██████████████████████████████████▉                                         | 46/100 [2:53:27<3:44:15, 249.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Loss 2.8884 Accuracy 0.1680\n",
      "Time taken for 1 epoch: 170.8151113986969 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|███████████████████████████████████▋                                        | 47/100 [2:56:19<3:19:28, 225.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Loss 2.8881 Accuracy 0.1685\n",
      "Time taken for 1 epoch: 171.3224914073944 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████████████████████████████████████▍                                       | 48/100 [2:59:11<3:01:38, 209.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Loss 2.8883 Accuracy 0.1684\n",
      "Time taken for 1 epoch: 171.703040599823 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|█████████████████████████████████████▏                                      | 49/100 [3:02:02<2:48:29, 198.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Loss 2.8885 Accuracy 0.1683\n",
      "Time taken for 1 epoch: 171.70091104507446 secs\n",
      "\n",
      "Epoch 50 Loss 2.8881 Accuracy 0.1684\n",
      "Time taken for 1 epoch: 171.6985321044922 secs\n",
      "\n",
      "writing file..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████████████████████                                      | 50/100 [3:09:28<3:47:04, 272.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.16470125786163523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|██████████████████████████████████████▊                                     | 51/100 [3:12:19<3:17:44, 242.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Loss 2.8884 Accuracy 0.1684\n",
      "Time taken for 1 epoch: 171.26714849472046 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|███████████████████████████████████████▌                                    | 52/100 [3:15:11<2:56:50, 221.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 Loss 2.8882 Accuracy 0.1685\n",
      "Time taken for 1 epoch: 171.77669143676758 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|████████████████████████████████████████▎                                   | 53/100 [3:18:03<2:41:37, 206.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Loss 2.8885 Accuracy 0.1685\n",
      "Time taken for 1 epoch: 171.9012541770935 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████████████████████████████████████████                                   | 54/100 [3:20:55<2:30:13, 195.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 Loss 2.8878 Accuracy 0.1685\n",
      "Time taken for 1 epoch: 171.68867230415344 secs\n",
      "\n",
      "Epoch 55 Loss 2.8881 Accuracy 0.1684\n",
      "Time taken for 1 epoch: 171.70012617111206 secs\n",
      "\n",
      "writing file..\n",
      "Recall: 0.1829140461215933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████████████████████████████████████████▊                                  | 55/100 [3:28:45<3:28:38, 278.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint for epoch 55 at ./checkpoints/model_A\\ckpt-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|██████████████████████████████████████████▌                                 | 56/100 [3:31:37<3:00:34, 246.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 Loss 2.8881 Accuracy 0.1685\n",
      "Time taken for 1 epoch: 171.63407278060913 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|███████████████████████████████████████████▎                                | 57/100 [3:34:30<2:40:50, 224.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 Loss 2.8883 Accuracy 0.1684\n",
      "Time taken for 1 epoch: 173.44537734985352 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|████████████████████████████████████████████                                | 58/100 [3:37:22<2:26:06, 208.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 Loss 2.8880 Accuracy 0.1685\n",
      "Time taken for 1 epoch: 171.98773503303528 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|████████████████████████████████████████████▊                               | 59/100 [3:40:14<2:15:04, 197.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 Loss 2.8879 Accuracy 0.1685\n",
      "Time taken for 1 epoch: 171.81480526924133 secs\n",
      "\n",
      "Epoch 60 Loss 2.8880 Accuracy 0.1683\n",
      "Time taken for 1 epoch: 171.6340618133545 secs\n",
      "\n",
      "writing file..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████▌                              | 60/100 [3:47:42<3:01:51, 272.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.16561844863731656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████████████████████████████████████████████▎                             | 61/100 [3:50:35<2:37:43, 242.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 Loss 2.8880 Accuracy 0.1685\n",
      "Time taken for 1 epoch: 172.2824740409851 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|███████████████████████████████████████████████                             | 62/100 [3:53:26<2:20:09, 221.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 Loss 2.8880 Accuracy 0.1674\n",
      "Time taken for 1 epoch: 171.45160627365112 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|███████████████████████████████████████████████▉                            | 63/100 [3:56:18<2:07:18, 206.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 Loss 2.8880 Accuracy 0.1679\n",
      "Time taken for 1 epoch: 171.662211894989 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|████████████████████████████████████████████████▋                           | 64/100 [3:59:09<1:57:35, 196.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 Loss 2.8883 Accuracy 0.1683\n",
      "Time taken for 1 epoch: 171.64720368385315 secs\n",
      "\n",
      "Epoch 65 Loss 2.8879 Accuracy 0.1684\n",
      "Time taken for 1 epoch: 172.17649388313293 secs\n",
      "\n",
      "writing file..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|████████████████████████████████████████████████▋                           | 64/100 [4:08:02<2:19:31, 232.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.18029350104821804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_recall = 0\n",
    "early_stop_cnt = 0\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    start = time.time()\n",
    "    \n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "\n",
    "    for sample in train_dataset:\n",
    "        train_step(model_A, sample['qa'], sample['qb'], sample['im'], sample['posdata'], sample['labels'])\n",
    "        \n",
    "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "    \n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n",
    "    \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        test_recall = eval_step(model_A)\n",
    "        if(test_recall > max_recall):\n",
    "            max_recall = test_recall\n",
    "            ckpt_save_path = ckpt_manager.save()\n",
    "            print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                                 ckpt_save_path))\n",
    "        else:\n",
    "            early_stop_cnt += 1\n",
    "        \n",
    "    if early_stop_cnt == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRNet(tf.keras.Model):\n",
    "    def __init__(self, num_layers=8, im_shape=(224, 224, 3), posdata_shape=(32, 32, 2)):\n",
    "        super(DRNet, self).__init__()\n",
    "        \n",
    "        #self.appr = AppearanceSubnet(input_shape=im_shape)\n",
    "        self.spatial = SpatialSubnet(input_shape=posdata_shape)\n",
    "        #self.combine = CombineSubnets()\n",
    "        #self.dr = DRModule(num_layers=num_layers)\n",
    "        self.temp_fc = tf.keras.layers.Dense(70)\n",
    "        self.softmax = tf.keras.layers.Softmax()\n",
    "        \n",
    "    def call(self, qa, qb, im, posdata):\n",
    "        #fc8 = self.appr(im)\n",
    "        conv3_p = self.spatial(posdata)\n",
    "        #qr0 = self.combine(fc8, conv3_p)\n",
    "        #qr = self.dr(qa, qb, qr0)\n",
    "        qr = self.temp_fc(conv3_p[:, 0, 0, :])\n",
    "        out = self.softmax(qr)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_S = DRNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.01491421 0.0140573  0.01439006 ... 0.01386466 0.01364683 0.01480633]\n",
      " [0.01435929 0.0144551  0.01473911 ... 0.01404168 0.01382555 0.01458371]\n",
      " [0.01478864 0.01382029 0.01425514 ... 0.01338174 0.014387   0.0149344 ]\n",
      " ...\n",
      " [0.01565182 0.01440093 0.01487634 ... 0.01333662 0.01275025 0.01625833]\n",
      " [0.01427076 0.01435189 0.0146712  ... 0.01425032 0.01381755 0.01472828]\n",
      " [0.0147174  0.01417669 0.01456229 ... 0.01369194 0.01376129 0.0159472 ]], shape=(32, 70), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for sample in train_dataset:\n",
    "    print(model_S(sample['qa'], sample['qb'], sample['im'], sample['posdata']))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/model_S\"\n",
    "ckpt = tf.train.Checkpoint(model_S=model_S, optimizer=optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, qa, qb, im, posdata, label):\n",
    "    loss = 0\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        y = model(qa, qb, im, posdata)\n",
    "        loss += loss_object(label, y)\n",
    "        \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(label, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(model, out_path='temp.npz', num_dets=50, ov_thresh=0.5):\n",
    "    test_model(model, out_path)\n",
    "    test_recall = eval_recall(out_path, num_dets, ov_thresh)\n",
    "    return test_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▊                                                                               | 1/100 [00:47<1:18:05, 47.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 2.2920 Accuracy 0.3820\n",
      "Time taken for 1 epoch: 47.3262140750885 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▌                                                                              | 2/100 [01:24<1:12:08, 44.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss 2.0493 Accuracy 0.4305\n",
      "Time taken for 1 epoch: 36.71003818511963 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▍                                                                             | 3/100 [01:48<1:01:40, 38.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss 1.9615 Accuracy 0.4428\n",
      "Time taken for 1 epoch: 24.00798225402832 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▎                                                                              | 4/100 [02:03<50:01, 31.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss 1.8659 Accuracy 0.4611\n",
      "Time taken for 1 epoch: 15.126852989196777 secs\n",
      "\n",
      "Epoch 5 Loss 1.7505 Accuracy 0.4827\n",
      "Time taken for 1 epoch: 7.49103569984436 secs\n",
      "\n",
      "writing file..\n",
      "Recall: 0.11386268343815513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███▉                                                                           | 5/100 [06:37<2:45:00, 104.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving checkpoint for epoch 5 at ./checkpoints/model_S\\ckpt-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▊                                                                           | 6/100 [07:17<2:13:04, 84.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss 1.6153 Accuracy 0.5111\n",
      "Time taken for 1 epoch: 39.9422709941864 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▌                                                                          | 7/100 [07:52<1:48:25, 69.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss 1.4691 Accuracy 0.5447\n",
      "Time taken for 1 epoch: 34.871830224990845 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▍                                                                         | 8/100 [08:11<1:23:37, 54.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss 1.3153 Accuracy 0.5819\n",
      "Time taken for 1 epoch: 18.47900080680847 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████▏                                                                        | 9/100 [08:21<1:02:29, 41.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss 1.1824 Accuracy 0.6195\n",
      "Time taken for 1 epoch: 9.998266220092773 secs\n",
      "\n",
      "Epoch 10 Loss 1.0674 Accuracy 0.6535\n",
      "Time taken for 1 epoch: 8.220048427581787 secs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|███████▏                                                                        | 9/100 [12:05<2:02:19, 80.65s/it]\n"
     ]
    }
   ],
   "source": [
    "max_recall = 0\n",
    "early_stop_cnt = 0\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    start = time.time()\n",
    "    \n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "\n",
    "    for sample in train_dataset:\n",
    "        train_step(model_S, sample['qa'], sample['qb'], sample['im'], sample['posdata'], sample['labels'])\n",
    "    \n",
    "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "    \n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n",
    "    \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        test_recall = eval_step(model_S)\n",
    "        if(test_recall > max_recall):\n",
    "            max_recall = test_recall\n",
    "            ckpt_save_path = ckpt_manager.save()\n",
    "            print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                                 ckpt_save_path))\n",
    "        else:\n",
    "            early_stop_cnt += 1\n",
    "        \n",
    "    if early_stop_cnt == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appearance + Spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/model_A\"\n",
    "ckpt = tf.train.Checkpoint(model_A=model_A, optimizer=optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.get_layer(index=0).weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/model_S\"\n",
    "ckpt = tf.train.Checkpoint(model_S=model_S, optimizer=optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_S.get_layer(index=0).weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRNet(tf.keras.Model):\n",
    "    def __init__(self, num_layers=8, im_shape=(224, 224, 3), posdata_shape=(32, 32, 2)):\n",
    "        super(DRNet, self).__init__()\n",
    "        \n",
    "        self.appr = AppearanceSubnet(input_shape=im_shape)\n",
    "        self.spatial = SpatialSubnet(input_shape=posdata_shape)\n",
    "        self.combine = CombineSubnets()\n",
    "        #self.dr = DRModule(num_layers=num_layers)\n",
    "        self.temp_fc = tf.keras.layers.Dense(70)\n",
    "        self.softmax = tf.keras.layers.Softmax()\n",
    "        \n",
    "    def call(self, qa, qb, im, posdata):\n",
    "        fc8 = self.appr(im)\n",
    "        conv3_p = self.spatial(posdata)\n",
    "        qr0 = self.combine(fc8, conv3_p)\n",
    "        #qr = self.dr(qa, qb, qr0)\n",
    "        qr = self.temp_fc(qr0)\n",
    "        out = self.softmax(qr)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_AS = DRNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in train_dataset:\n",
    "    print(model_AS(sample['qa'], sample['qb'], sample['im'], sample['posdata']))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(model_AS.get_layer(index=0).weights)):\n",
    "    model_AS.get_layer(index=0).weights[i].assign(model_A.get_layer(index=0).weights[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_AS.get_layer(index=0).weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(model_AS.get_layer(index=1).weights)):\n",
    "    model_AS.get_layer(index=1).weights[i].assign(model_S.get_layer(index=0).weights[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_AS.get_layer(index=1).weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in train_dataset:\n",
    "    print(model_AS(sample['qa'], sample['qb'], sample['im'], sample['posdata']))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/model_AS\"\n",
    "ckpt = tf.train.Checkpoint(model_AS=model_AS, optimizer=optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, qa, qb, im, posdata, label):\n",
    "    loss = 0\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        y = model(qa, qb, im, posdata)\n",
    "        loss += loss_object(label, y)\n",
    "        \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(label, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(model, out_path='temp.npz', num_dets=50, ov_thresh=0.5):\n",
    "    test_model(model, out_path)\n",
    "    test_recall = eval_recall(out_path, num_dets, ov_thresh)\n",
    "    return test_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_recall = 0\n",
    "early_stop_cnt = 0\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    start = time.time()\n",
    "    \n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "\n",
    "    for sample in train_dataset:\n",
    "        train_step(model_AS, sample['qa'], sample['qb'], sample['im'], sample['posdata'], sample['labels'])\n",
    "        \n",
    "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "    \n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n",
    "    \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        test_recall = eval_step(model_AS)\n",
    "        if(test_recall > max_recall):\n",
    "            max_recall = test_recall\n",
    "            ckpt_save_path = ckpt_manager.save()\n",
    "            print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                                 ckpt_save_path))\n",
    "        else:\n",
    "            early_stop_cnt += 1\n",
    "        \n",
    "    if early_stop_cnt == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appearance + Spatial + DRNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/model_AS\"\n",
    "ckpt = tf.train.Checkpoint(model_AS=model_AS, optimizer=optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_AS.get_layer(index=0).weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_AS.get_layer(index=1).weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_AS.get_layer(index=2).weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DRNet(tf.keras.Model):\n",
    "    def __init__(self, num_layers=8, im_shape=(224, 224, 3), posdata_shape=(32, 32, 2)):\n",
    "        super(DRNet, self).__init__()\n",
    "        \n",
    "        self.appr = AppearanceSubnet(input_shape=im_shape)\n",
    "        self.spatial = SpatialSubnet(input_shape=posdata_shape)\n",
    "        self.combine = CombineSubnets()\n",
    "        self.dr = DRModule(num_layers=num_layers)\n",
    "        self.softmax = tf.keras.layers.Softmax()\n",
    "        \n",
    "    def call(self, qa, qb, im, posdata):\n",
    "        fc8 = self.appr(im)\n",
    "        conv3_p = self.spatial(posdata)\n",
    "        qr0 = self.combine(fc8, conv3_p)\n",
    "        qr = self.dr(qa, qb, qr0)\n",
    "        out = self.softmax(qr)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ASD = DRNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in train_dataset:\n",
    "    print(model_ASD(sample['qa'], sample['qb'], sample['im'], sample['posdata']))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(model_ASD.get_layer(index=0).weights)):\n",
    "    model_ASD.get_layer(index=0).weights[i].assign(model_AS.get_layer(index=0).weights[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ASD.get_layer(index=0).weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(model_ASD.get_layer(index=1).weights)):\n",
    "    model_ASD.get_layer(index=1).weights[i].assign(model_AS.get_layer(index=1).weights[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ASD.get_layer(index=1).weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(model_ASD.get_layer(index=2).weights)):\n",
    "    model_ASD.get_layer(index=2).weights[i].assign(model_AS.get_layer(index=2).weights[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_ASD.get_layer(index=2).weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in train_dataset:\n",
    "    print(model_ASD(sample['qa'], sample['qb'], sample['im'], sample['posdata']))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./checkpoints/model_ASD\"\n",
    "ckpt = tf.train.Checkpoint(model_ASD=model_ASD, optimizer=optimizer)\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, qa, qb, im, posdata, label):\n",
    "    loss = 0\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        y = model(qa, qb, im, posdata)\n",
    "        loss += loss_object(label, y)\n",
    "        \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(label, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_step(model, out_path='temp.npz', num_dets=50, ov_thresh=0.5):\n",
    "    test_model(model, out_path)\n",
    "    test_recall = eval_recall(out_path, num_dets, ov_thresh)\n",
    "    return test_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_recall = 0\n",
    "early_stop_cnt = 0\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    start = time.time()\n",
    "    \n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "\n",
    "    for sample in train_dataset:\n",
    "        train_step(model_ASD, sample['qa'], sample['qb'], sample['im'], sample['posdata'], sample['labels'])\n",
    "        \n",
    "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "    \n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n",
    "    \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        test_recall = eval_step(model_ASD)\n",
    "        if(test_recall > max_recall):\n",
    "            max_recall = test_recall\n",
    "            ckpt_save_path = ckpt_manager.save()\n",
    "            print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                                 ckpt_save_path))\n",
    "        else:\n",
    "            early_stop_cnt += 1\n",
    "        \n",
    "    if early_stop_cnt == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_2.0",
   "language": "python",
   "name": "tf_2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
